{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "from API_utils.dataset_FEGS import API_FEGS_Class\n",
    "from API_utils.dataset_api import API_Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = \"C:/Users/asus/Desktop/API/dataset/one_to_one.xls\"\n",
    "DATASET_MAT_PATH = \"C:/Users/asus/Desktop/API/dataset/one_to_one.mat\"\n",
    "TEST_DATASET_PATH = \"C:/Users/asus/Desktop/API/dataset/test.xlsx\"\n",
    "TEST_DATASET_MAT_PATH = \"C:/Users/asus/Desktop/API/dataset/test.mat\"\n",
    "SAVE_MODEL_PATH = \"C:/Users/asus/Desktop/API/Model/\"\n",
    "CSV_PATH = \"C:/Users/asus/Desktop/API/dataset/Dataset.csv\"\n",
    "DEVICE= torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "EPOCH = 100\n",
    "lr=0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = API_FEGS_Class(DATASET_PATH,DATASET_MAT_PATH,'abc')\n",
    "# test_data = API_FEGS_Class(TEST_DATASET_PATH,TEST_DATASET_MAT_PATH,'test')\n",
    "\n",
    "train_data = API_Class(CSV_PATH)\n",
    "test_data = API_Class(CSV_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpatialGatingUnit(nn.Module):  # [-1,256,256]\n",
    "    def __init__(self, d_ffn, seq_len):\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(d_ffn)   # [-1,256,256]->[-1,256,512]\n",
    "        self.spatial_proj = nn.Conv1d(seq_len, seq_len, kernel_size=1) # [-1,256,512]->[-1,256,512]\n",
    "        nn.init.constant_(self.spatial_proj.bias, 1.0)  # 偏差\n",
    " \n",
    "    def forward(self, x):\n",
    "        # chunk(arr, size)接收两个参数，一个是原数组，一个是分块的大小size，默认值为1，\n",
    "        # 原数组中的元素会按照size的大小从头开始分块，每一块组成一个新数组，如果最后元素个数不足size的大小，那么它们会组成一个快。\n",
    "        u, v = x.chunk(2, dim=-1)\n",
    "        v = self.norm(v)\n",
    "        v = self.spatial_proj(v)\n",
    "        out = u * v\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class gMLPBlock(nn.Module):\n",
    "    def __init__(self, d_model, d_ffn, seq_len):\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "        self.channel_proj1 = nn.Linear(d_model, d_ffn * 2) # (256, d_ffn * 2=1024)  [-1,256,1024]\n",
    "        self.sgu = SpatialGatingUnit(d_ffn, seq_len)   #\n",
    "        self.channel_proj2 = nn.Linear(d_ffn, d_model)\n",
    " \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        x = self.norm(x)     # [-1,256,256]\n",
    "        x = F.gelu(self.channel_proj1(x))  # GELU激活函数 [-1,256,256]\n",
    "        x = self.sgu(x)   # [-1,256,256]\n",
    "        x = self.channel_proj2(x)\n",
    "        out = x + residual\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class gMLP(nn.Module):\n",
    "    def __init__(self, d_model=256, d_ffn=512, seq_len=256, num_layers=6):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            *[gMLPBlock(d_model, d_ffn, seq_len) for _ in range(num_layers)]\n",
    "        )\n",
    "        # [gMLPBlock(d_model=256, d_ffn=512, seq_len=256) for _ in range(num_layers)]\n",
    " \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class gMLPForImageClassification(gMLP):\n",
    "    def __init__(\n",
    "        self,\n",
    "        image_size=256+64,\n",
    "        patch_size=16,\n",
    "        in_channels=1,\n",
    "        num_classes=2,\n",
    "        d_model=256,\n",
    "        d_ffn=512,\n",
    "        seq_len=256,\n",
    "        num_layers=6,\n",
    "    ):\n",
    "        # num_patches = check_sizes(image_size, patch_size)  # num_patches=256\n",
    "        super().__init__(d_model, d_ffn, seq_len, num_layers)\n",
    "        self.patcher = nn.Conv1d(\n",
    "            in_channels, d_model, kernel_size=patch_size, stride=patch_size\n",
    "        )  # [2, 3, 256, 256] -> [2, 256, 16, 16]\n",
    "        self.classifier = nn.Linear(d_model, num_classes)\n",
    " \n",
    "    def forward(self, x):\n",
    "        # a = x.shape = [2,3,256,256]\n",
    "        patches = self.patcher(x)\n",
    "        batch_size, num_channels, _, _ = patches.shape  # [2,256,16,16]\n",
    "        patches = patches.permute(0, 2, 3, 1)  # 将tensor的维度换位 [2,256,16,16]->[2,16,16,256]\n",
    "        patches = patches.view(batch_size, -1, num_channels) # 转为(2,-1,256)  即为[2,256,256]\n",
    "        # a = patches.shape\n",
    "        embedding = self.model(patches)\n",
    "        # a = embedding.shape = [2,256,256]\n",
    " \n",
    "        embedding = embedding.mean(dim=1)\n",
    "        out = self.classifier(embedding)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_loader = DataLoader(train_data,batch_size=1,shuffle=True)\n",
    "test_data_loader = DataLoader(test_data,batch_size=1,shuffle=True)\n",
    "Net = gMLPForImageClassification().to(DEVICE)\n",
    "optimizer = optim.AdamW(params=Net.parameters(),lr=lr)\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model_path,test_data_loader,device=DEVICE):\n",
    "    count=0\n",
    "    acc = 0\n",
    "    model = torch.load(model_path)\n",
    "    for idx, data in enumerate(test_data_loader):\n",
    "        api_input, api_label = data\n",
    "        count+=1\n",
    "        rna_input = api_input[:,0:256+64]\n",
    "        # print(rna_input)\n",
    "        protein_input = api_input[:,256+64:]\n",
    "        rna_input = torch.unsqueeze(rna_input,dim=0)\n",
    "        protein_input = torch.unsqueeze(protein_input,dim=0)\n",
    "        #api_label = torch.unsqueeze(api_label,dim=0)\n",
    "        rna_input = rna_input.to(dtype=torch.float32).to(DEVICE)\n",
    "        protein_input = protein_input.to(dtype=torch.float32).to(DEVICE)\n",
    "        output = model(rna_input,protein_input).to(DEVICE)\n",
    "        # print(torch.round(torch.sigmoid(output)))\n",
    "        if(torch.round(torch.sigmoid(output))==api_label[0]):\n",
    "            acc+=1\n",
    "\n",
    "    \n",
    "    print(\"Accuracy\",acc/count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1160 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 4, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-f75435a9907f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mrna_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrna_input\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mprotein_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprotein_input\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapi_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m         \u001b[1;31m# print(output)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-19-906ebf6e0b65>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[1;31m# a = x.shape = [2,3,256,256]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mpatches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpatcher\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_channels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpatches\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m  \u001b[1;31m# [2,256,16,16]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m         \u001b[0mpatches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpatches\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# 将tensor的维度换位 [2,256,16,16]->[2,16,16,256]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mpatches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpatches\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_channels\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 转为(2,-1,256)  即为[2,256,256]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 4, got 2)"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCH):\n",
    "    for data in tqdm(train_data_loader):\n",
    "        api_input, api_label = data\n",
    "        # print(api_input.shape)\n",
    "        # print(api_input)\n",
    "        # break\n",
    "        api_input = api_input.to(DEVICE)\n",
    "        api_input = api_input.to(dtype=torch.float32)\n",
    "        api_label = api_label.to(DEVICE)\n",
    "        rna_input = api_input[:,0:64+256]\n",
    "        # print(api_input.shape)\n",
    "        protein_input = api_input[:,64+256:]\n",
    "        rna_input = torch.unsqueeze(rna_input,dim=0)\n",
    "        protein_input = torch.unsqueeze(protein_input,dim=0)\n",
    "\n",
    "        api_label = torch.unsqueeze(api_label,dim=0).to(dtype=torch.float32)\n",
    "        rna_input = rna_input.to(dtype=torch.float32)\n",
    "        protein_input = protein_input.to(dtype=torch.float32)\n",
    "        output = Net(api_input)\n",
    "        # print(output)\n",
    "        optimizer.zero_grad()    \n",
    "        Loss = loss_fn(output, api_label)  \n",
    "        Loss.backward()  \n",
    "        optimizer.step()\n",
    "    \n",
    "    print(\"Loss\",Loss.item())\n",
    "    save_path = SAVE_MODEL_PATH+f'Epoch={epoch}_lr={lr}.pth'\n",
    "    torch.save(Net, save_path)\n",
    "    evaluate(SAVE_MODEL_PATH+f'Epoch={epoch}_lr={lr}.pth',test_data_loader)\n",
    "    # break\n",
    "    \n",
    "torch.save(Net, SAVE_MODEL_PATH+f'Epoch={epoch}_lr={lr}_final.pth')\n",
    "print('CSX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=torch.load(SAVE_MODEL_PATH+f'Epoch={epoch}_lr={lr}_final.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "acc=0\n",
    "count=0\n",
    "for idx, data in enumerate(test_data_loader):\n",
    "    api_input, api_label = data\n",
    "    count+=1\n",
    "    rna_input = api_input[:,0:64]\n",
    "    protein_input = api_input[:,64:909]\n",
    "    rna_input = torch.unsqueeze(rna_input,dim=0)\n",
    "    protein_input = torch.unsqueeze(protein_input,dim=0)\n",
    "    #api_label = torch.unsqueeze(api_label,dim=0)\n",
    "    rna_input = rna_input.to(dtype=torch.float32)\n",
    "    protein_input = protein_input.to(dtype=torch.float32)\n",
    "    output = model(rna_input,protein_input)\n",
    "    if(torch.argmax(output)==api_label[0]):\n",
    "        acc+=1\n",
    "\n",
    "    \n",
    "print(acc/count)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.0 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "88279d2366fe020547cde40dd65aa0e3aa662a6ec1f3ca12d88834876c85e1a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
