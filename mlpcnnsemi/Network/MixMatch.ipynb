{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import math\n",
    "from API_utils.dataset_FEGS import API_FEGS_Class\n",
    "from API_utils.dataset_api import API_Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = \"C:/Users/asus/Desktop/API/dataset/one_to_one.xls\"\n",
    "DATASET_MAT_PATH = \"C:/Users/asus/Desktop/API/dataset/one_to_one.mat\"\n",
    "TEST_DATASET_PATH = \"C:/Users/asus/Desktop/API/dataset/test.xlsx\"\n",
    "TEST_DATASET_MAT_PATH = \"C:/Users/asus/Desktop/API/dataset/test.mat\"\n",
    "SAVE_MODEL_PATH = \"C:/Users/asus/Desktop/API/Model/\"\n",
    "CSV_PATH = \"C:/Users/asus/Desktop/API/dataset/Dataset0.csv\"\n",
    "DEVICE= torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "EPOCH = 100\n",
    "lr=0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = API_FEGS_Class(DATASET_PATH,DATASET_MAT_PATH,'abc')\n",
    "# test_data = API_FEGS_Class(TEST_DATASET_PATH,TEST_DATASET_MAT_PATH,'test')\n",
    "\n",
    "\n",
    "train_data = API_Class(CSV_PATH)\n",
    "test_data = API_Class(CSV_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, stride, dropRate=0.0, activate_before_residual=False):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.bn1 = nn.BatchNorm1d(in_planes, momentum=0.001)\n",
    "        self.relu1 = nn.LeakyReLU(negative_slope=0.1, inplace=True)\n",
    "        self.conv1 = nn.Conv1d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm1d(out_planes, momentum=0.001)\n",
    "        self.relu2 = nn.LeakyReLU(negative_slope=0.1, inplace=True)\n",
    "        self.conv2 = nn.Conv1d(out_planes, out_planes, kernel_size=3, stride=1,\n",
    "                               padding=1, bias=False)\n",
    "        self.droprate = dropRate\n",
    "        self.equalInOut = (in_planes == out_planes)\n",
    "        self.convShortcut = (not self.equalInOut) and nn.Conv1d(in_planes, out_planes, kernel_size=1, stride=stride,\n",
    "                               padding=0, bias=False) or None\n",
    "        self.activate_before_residual = activate_before_residual\n",
    "    def forward(self, x):\n",
    "        if not self.equalInOut and self.activate_before_residual == True:\n",
    "            x = self.relu1(self.bn1(x))\n",
    "        else:\n",
    "            out = self.relu1(self.bn1(x))\n",
    "        out = self.relu2(self.bn2(self.conv1(out if self.equalInOut else x)))\n",
    "        if self.droprate > 0:\n",
    "            out = F.dropout(out, p=self.droprate, training=self.training)\n",
    "        out = self.conv2(out)\n",
    "        return torch.add(x if self.equalInOut else self.convShortcut(x), out)\n",
    "\n",
    "class NetworkBlock(nn.Module):\n",
    "    def __init__(self, nb_layers, in_planes, out_planes, block, stride, dropRate=0.0, activate_before_residual=False):\n",
    "        super(NetworkBlock, self).__init__()\n",
    "        self.layer = self._make_layer(block, in_planes, out_planes, nb_layers, stride, dropRate, activate_before_residual)\n",
    "    def _make_layer(self, block, in_planes, out_planes, nb_layers, stride, dropRate, activate_before_residual):\n",
    "        layers = []\n",
    "        for i in range(int(nb_layers)):\n",
    "            layers.append(block(i == 0 and in_planes or out_planes, out_planes, i == 0 and stride or 1, dropRate, activate_before_residual))\n",
    "        return nn.Sequential(*layers)\n",
    "    def forward(self, x):\n",
    "        return self.layer(x)\n",
    "\n",
    "class WideResNet(nn.Module):\n",
    "    def __init__(self, num_classes, depth=28, widen_factor=2, dropRate=0.0):\n",
    "        super(WideResNet, self).__init__()\n",
    "        # nChannels = [16, 16*widen_factor, 32*widen_factor, 64*widen_factor]\n",
    "        nChannels = [640, 640, 320,160]\n",
    "        assert((depth - 4) % 6 == 0)\n",
    "        n = (depth - 4) / 6\n",
    "        block = BasicBlock\n",
    "        # 1st conv before any network block\n",
    "        self.conv1 = nn.Conv1d(1, nChannels[0], kernel_size=3, stride=1,\n",
    "                               padding=1, bias=False)\n",
    "        # 1st block\n",
    "        self.block1 = NetworkBlock(n, nChannels[0], nChannels[1], block, 1, dropRate, activate_before_residual=True)\n",
    "        # 2nd block\n",
    "        self.block2 = NetworkBlock(n, nChannels[1], nChannels[2], block, 2, dropRate)\n",
    "        # 3rd block\n",
    "        self.block3 = NetworkBlock(n, nChannels[2], nChannels[3], block, 2, dropRate)\n",
    "        # global average pooling and classifier\n",
    "        self.bn1 = nn.BatchNorm1d(nChannels[3], momentum=0.001)\n",
    "        self.relu = nn.LeakyReLU(negative_slope=0.1, inplace=True)\n",
    "        self.fc = nn.Linear(nChannels[3], num_classes)\n",
    "        self.nChannels = nChannels[3]\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv1d):\n",
    "                n = m.kernel_size[0] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm1d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight.data)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        out = self.conv1(x)\n",
    "\n",
    "        out = self.block1(out)\n",
    "        out = self.block2(out)\n",
    "        out = self.block3(out)\n",
    "\n",
    "        out = self.relu(self.bn1(out))\n",
    "\n",
    "        out = F.avg_pool1d(out, 128)\n",
    "        # print(out.shape)\n",
    "        out = out.view(-1, self.nChannels)\n",
    "        # print(out.shape)\n",
    "        out = self.fc(out)\n",
    "        # print(out.shape)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_loader = DataLoader(train_data,batch_size=1,shuffle=True)\n",
    "test_data_loader = DataLoader(test_data,batch_size=1,shuffle=True)\n",
    "Net = WideResNet(num_classes=1).to(DEVICE)\n",
    "optimizer = optim.AdamW(params=Net.parameters(),lr=lr)\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model_path,test_data_loader,device=DEVICE):\n",
    "    count=0\n",
    "    acc = 0\n",
    "    model = torch.load(model_path)\n",
    "    for idx, data in enumerate(test_data_loader):\n",
    "        api_input, api_label = data\n",
    "        count+=1\n",
    "        \n",
    "        api_input = api_input.to(DEVICE)\n",
    "        api_input = api_input.to(dtype=torch.float32)\n",
    "        # print(rna_input)\n",
    "        rna_input = api_input[:,0:256+64]\n",
    "        protein_input = api_input[:,256+64:]\n",
    "        rna_input = torch.unsqueeze(rna_input,dim=0)\n",
    "        protein_input = torch.unsqueeze(protein_input,dim=0)\n",
    "        #api_label = torch.unsqueeze(api_label,dim=0)\n",
    "        rna_input = rna_input.to(dtype=torch.float32).to(DEVICE)\n",
    "        protein_input = protein_input.to(dtype=torch.float32).to(DEVICE)\n",
    "        output = model(api_input).to(DEVICE)\n",
    "        # print(torch.round(torch.sigmoid(output)))\n",
    "        if(torch.round(torch.sigmoid(output))==api_label[0]):\n",
    "            acc+=1\n",
    "\n",
    "    \n",
    "    print(\"Accuracy\",acc/count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(EPOCH):\n",
    "    for data in tqdm(train_data_loader):\n",
    "        api_input, api_label = data\n",
    "        # print(api_input.shape)\n",
    "        # print(api_input)\n",
    "        # break\n",
    "        api_input = api_input.to(DEVICE)\n",
    "        api_input = api_input.to(dtype=torch.float32)\n",
    "        api_label = api_label.to(DEVICE)\n",
    "        rna_input = api_input[:,0:64+256]\n",
    "        # print(api_input.shape)\n",
    "        protein_input = api_input[:,64+256:]\n",
    "        rna_input = torch.unsqueeze(rna_input,dim=0)\n",
    "        protein_input = torch.unsqueeze(protein_input,dim=0)\n",
    "\n",
    "        api_label = torch.unsqueeze(api_label,dim=0).to(dtype=torch.float32)\n",
    "        rna_input = rna_input.to(dtype=torch.float32)\n",
    "        protein_input = protein_input.to(dtype=torch.float32)\n",
    "        output = Net(api_input)\n",
    "        # print(output)\n",
    "        optimizer.zero_grad()    \n",
    "        Loss = loss_fn(output, api_label)  \n",
    "        Loss.backward()  \n",
    "        optimizer.step()\n",
    "    \n",
    "    print(\"Loss\",Loss.item())\n",
    "    save_path = SAVE_MODEL_PATH+f'Epoch={epoch}_lr={lr}.pth'\n",
    "    torch.save(Net, save_path)\n",
    "    evaluate(SAVE_MODEL_PATH+f'Epoch={epoch}_lr={lr}.pth',test_data_loader)\n",
    "    # break\n",
    "    \n",
    "torch.save(Net, SAVE_MODEL_PATH+f'Epoch={epoch}_lr={lr}_final.pth')\n",
    "print('CSX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=torch.load(SAVE_MODEL_PATH+f'Epoch={epoch}_lr={lr}_final.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "acc=0\n",
    "count=0\n",
    "for idx, data in enumerate(test_data_loader):\n",
    "    api_input, api_label = data\n",
    "    count+=1\n",
    "    rna_input = api_input[:,0:64]\n",
    "    protein_input = api_input[:,64:909]\n",
    "    rna_input = torch.unsqueeze(rna_input,dim=0)\n",
    "    protein_input = torch.unsqueeze(protein_input,dim=0)\n",
    "    #api_label = torch.unsqueeze(api_label,dim=0)\n",
    "    rna_input = rna_input.to(dtype=torch.float32)\n",
    "    protein_input = protein_input.to(dtype=torch.float32)\n",
    "    output = model(rna_input,protein_input)\n",
    "    if(torch.argmax(output)==api_label[0]):\n",
    "        acc+=1\n",
    "\n",
    "    \n",
    "print(acc/count)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.0 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "88279d2366fe020547cde40dd65aa0e3aa662a6ec1f3ca12d88834876c85e1a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
